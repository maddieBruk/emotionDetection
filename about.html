<!doctype html>
<html lang="en">
  <head>
   <!--- <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-giJF6kkoqNQ00vy+HMDP7azOuL0xtbfIcaT9wjKHr8RbDVddVHyTfAAsrekwKmP1" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">-->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-H0NW5Z2MYC"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-H0NW5Z2MYC');
    </script>
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&family=Xanh+Mono:ital@1&display=swap" rel="stylesheet">
    <style>
      @import url('https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&family=Xanh+Mono:ital@1&display=swap');
      </style>
    <title> Emotion Detection WebApp</title>
    <meta name="description" content="Simple Machine Learning Model into an WebApp using TensorFlow.js">
    <meta name="keywords" content="Machine Learning, TensorFlow.js">
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Audiowide">
    <style>
      body {
        font-family: "Audiowide", sans-serif;
        justify-content: center;
        margin:auto;
      }
      .content{
        max-width: 500px;
        margin: auto;
      }
      .red{
    color:#f94144;
  }
  .orange{
    color:#f3722c;
  }
  .yellow{
    color:#f9c74f
  }
  .green{
    color:#43aa8b;
  }
  .blue{
    color:#277da1;
  }
  .purple{
    color:#9b5de5;
  }
      </style>
     <nav>
      <ul style="list-style-type:none;">
        <li><a href="upload.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="bios.html">Bios</a></li>
      </ul>
      <!-- <body style="background-color:black;"> </body>  -->
    </nav>
  </head>

  <body style="background-color: black; margin: 4rem; color: white; font-size: 1.4rem;">
    <h1>About</h1>
      <p>A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. Basically, neural network algorithms help computers think and learn like humans.
      </p>
      <p>The whole idea of artificial neural networks is based on the concept of the structure and functions of a human brain. A human brain consists of neurons that process and transmit information between themselves.
        </p>
      <p>Our Baseline model (programmed with a k-nearest neighbors design)performed at ~50 %.Human accuracy is around 65 %, suggesting that we could do better. So we did. We used a vgg model, and first trained it 
      </p>
      <p>This project was done as a part of <a href=”https://www.inspiritai.com/”>Inspirit AI</a>, a 10-day intensive course in artificial intelligence. Within 48 hours we were able to  create the site, import our model, and develop this website from scratch. Read on to see what we learned and built!</p>
        <h1>Neural Networks</h1>
        <p>During the first week, we learned about neural networks. A neural network is a series of algorithms that tries to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. Neural networks are based on the concept of the structure and functions of a human brain. A human brain consists of neurons that process and transmit information between themselves.</p>
        <h1>Building Our Model</h1>

<h1>Initial Models</h1>
<p>First, we located the facial landmarks on each face (eyes, eyebrows, mouths), and used the distances between each pair of points as inputs into our models. The first models we tried included K-Nearest Neighbors, Logistic Regression, and later Decision Trees, which weren’t very effective (accuracies below). The first models we used were only made of simple layers that weren’t able to analyze the features of the images in detail. 

Table of accuracies:
KNN: ~46%
Log: ~56%
Decision Tree:~44%


By adding more layers and nodes for the data to cycle through, using trial and error we were able to come upon a set of hidden layers and nodes that effectively worked together. They created our:</p>.
<h1>Final Model</h1>
<p>Our Baseline model (programmed with a k-nearest neighbors design)performed at ~50 %. Human accuracy is around 65%, suggesting that we could do better. We used a transfer learning model that took the weights from ImageNet, training on our data using a 90/10 split. The model uses several convolutional layers to filter information from the euclidean distances between facial nodes and pixel data into channels to decide which features indicate the emotion on the person’s face.</p>
        
      <p>
        Within 48 hours we created the site , imported our model, and designed the website. None of this could have been possible without the guidance of Inspirit AI : https://www.inspiritai.com/ . Thank you so much for visiting our website!
      </p>
  </body>
</html>